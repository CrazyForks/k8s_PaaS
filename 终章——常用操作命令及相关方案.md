## 终章——常用操作命令及相关方案

> 本章节会增加一些在工作中常用的操作，以及开发交付的一些贴近场景的组件及工具代替原本教程中的内容



## 命令

### 查-POD级

K8s查日志信息（describe即启动时的描述，在最下面的Event里。logs是deploy写好的输出日志）

~~~
# 先找到对应的pod空间和名字，第一列是空间名（NAMESPACE），第二列是pod名（PODNAME）
kubectl get po -A | grep $PODNAME 
kubectl describe po -n$NAMESPACE $PODNAME
kubectl logs -n$NAMESPACE $PODNAME
# 进入到pod里
kubectl exec -it -n$NAMESPACE $PODNAME -- /bin/bash
~~~

k8s查找pod配置内容

~~~
kubectl get $DEPLOY -n$NAMESPACE -o yaml |grep $SEARCH_SOMETHINE
~~~

> 查看哪个名称空间中那个类型配置里有这个内容，-o yaml 输出yaml格式内容

查某个服务ip

~~~
kubectl get svc $DEPLOYNAME -n$NAMESPACE
~~~

k8s查找全部未运行成功的pod，-A指全部，owide可以看到是在哪个宿主下

~~~
kubectl get pod -Aowide | grep -ivE 'running|completed' 
~~~

更强大的查看未运行成功的命令，因为有的pod虽然处于running但还是0/1，即未就绪状态，下面命令能把未就绪的也过滤出来

~~~
IFS_OlD=$IFS;IFS=$'\n';for i in `kubectl get po -A -owide|grep -v NAME|grep -v Comple`;do desire=`echo $i|awk '{print $3}'|awk -F '/' '{print $1}'`;reality=`echo $i|awk '{print $3}'|awk -F '/' '{print $2}'`;if [[ "$desire" != "$reality" ]];then echo $i; fi; done;IFS=$IFS_OLD
~~~



### 查-NODE级

~~~
# 查看有多个节点
kubectl get nodes
# 查看集群信息
kubectl cluster-info
# 显示节点的资源使用情况
kubectl top node
~~~

查看node的资源使用情况

~~~
for node in `kubectl get node | awk '{print $1}'|grep -v NAME`;do echo "======$node"; echo "==Capacity:" ;kubectl describe  node $node | grep -A 12 "Capacity:" | grep -E "cpu:|memory:|nvidia.com\/gpu|vcuda-core|vcuda-memory:"; echo "=request&limit:"; kubectl describe node $node |grep -E "cpu | memory  |nvidia.com/gpu                             |vcuda-core               |vcuda-memory                " ;done
~~~





### 删（重启，遇事不决重启pod）

重启/删除不同空间下的不同条件的pod，-A看到全部

~~~
kubectl get pod -A | grep -E 'testA| testB' | awk '{print $1" "$2}' | while read line ; do kubectl delete pod -n $line ; done
~~~

> 可以先使用如下命令确认过滤出来的命名空间和pod是否一致，其中testA和testB是要过滤出来的pod名
>
> ~~~
> kubectl get pod -A | grep -E 'testA| testB' | awk '{print $1" "$2}' 
> ~~~
>
> 也可以使用如下方法来重启/删除不同命名空间下非running状态的pod
>
> ~~~
> kubectl get pod -A | grep -ivE 'running|completed' | awk '{print $1" "$2}' | while read line ; do kubectl delete pod -n $line ; done
> ~~~
>
> 强制重启，在delete pod 后面跟上 --grace-period=0 --force
>
> ~~~
> kubectl get pod -A | grep -ivE 'running|completed' | awk '{print $1" "$2}' | while read line ; do kubectl delete pod --grace-period=0 --force -n $line ; done
> ~~~
>
> 

全部重启/删除指定空间下的pod

~~~
kubectl delete pods --all -n$NAMESPACE
kubectl delete --all pods --namespace=$NAMESPACE
~~~

> 删除deploy之前可以先批量下载到一个文件，kubectl get deploy -n$NAMESPACE -o yaml > backup.yaml，然后再批量创建 kubectl create -f backup.yaml  -n$NAMESPACE

批量重启/删除指定空间下的pod

~~~
kubectl get pods -n$NAMESPACE| grep -v Running | awk '{print $1}' | xargs kubectl delete pod -n$NAMESPACE
~~~

> grep -v：反取没有running状态的pod
>
>  awk '{print $1}' ：stdin出来pod名字，传递给xargs使用



### 增

~~~
# 一般有现成的xxx.yaml文件，如下：
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
  - name: my-container
    image: nginx
    ports:
    - containerPort: 80
# 定义了一个名为 my-pod 的 Pod，它运行一个单独的容器，该容器使用 nginx 镜像，并且开放了 80 端口。
kubectl apply -f pod-example.yaml
# 或者直接运行命令
kubectl run my-pod --image=nginx --port=80
~~~



### 改

~~~
# 以上面创建的pod为例子，先导出yaml到本地。一般都有命名空间
kubectl get deploy -n$NAMESPACE my-deployment -o yaml > my-deployment.yaml

# 编辑现有的deploy，编辑后保存退出
kubectl edit deploy -n$NAMESPACE my-deployment

# 异常回滚方法一：
kubectl rollout undo deployment my-deployment
# 异常回滚方法二（apply之前保留的yaml文件，恢复旧配置）：
kubectl apply -f my-deployment.yaml
~~~



## 相关方案

### 关于监控

第七章节中，我们用到Promtheus来做监控，随着不断更新换代，为了更轻便、快速和简洁，以及更好的兼容其他不同程序，我们会采用Jaeger、ELK、Telegraf、Grafana的组合，再加上时序数据库InfluxDB。去掉Dashboard、Promtheus，因为客户只需要开发平台，而不需要频繁的修改k8s。

- **Jaeger：分布式追踪系统**（go语言），微服务系统更需要全链路跟踪，传统中，页面bug我们会开始排查前端问题，前端确认没问题说调用接口有错误日志，我们在去看后端，看完后端说底层就报错我们再去排查集群问题实在太耗费时间了，而全链路跟踪可以直接明了的看到是哪一环节的问题。
- **ELK：ES、Logstash、Kibana**
- **Telegraf：数据采集工具**（go语言），代替Prometheus
- **InfluxDB：时序数据库**（go语言），代替TSDB，各个指标都高于TSDB，随着推出时间越来越久，对市面上的产品也已经很兼容了。
- **Grafana：监控指标展示工具**（go语言）

##### 关于InfluxDB在实际应用中遇到的情况

在生产中由于机器数过多，使用默认配置的InfluxDB直接撑爆内存，重启内存会逐渐增大然后挂掉，也没办法进入，会报refused并提示确认是否在running，解决办法是直接把influx对应的路径下大的数据目录_retention结尾下的数字文件夹全部删掉，这样就有足够的空间，进入influx修改数据保存日期`alter retention policy "db_name__retention" on "db_name" duration 7d default`